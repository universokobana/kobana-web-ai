#!/usr/bin/env ruby
# frozen_string_literal: true

require 'pathname'
require 'yaml'

root_dir = Pathname.new(__dir__).parent
api_content_dir = root_dir.join('content', 'api', 'docs')
api_reference_file = root_dir.join('content', 'api_reference.md')
output_file = root_dir.join('views', 'pt-BR', 'api.md')
ignore_file = root_dir.join('content', 'ignore_docs.txt')

combined_content = ["# Kobana API Documentation\n\n"]
index_entries = []
section_counter = 0

def normalize_anchor(string)
  string.downcase
        .gsub(/[^a-z0-9\s-]/, '')  # Remove special characters
        .gsub(/\s+/, '-')          # Replace spaces with dahshes
        .gsub(/-+/, '-')           # Remove duplicate underscores
        .gsub(/^-|-$/, '')         # Remove leading/trailing underscores
end

# Load ignore patterns
ignore_patterns = []
if ignore_file.exist?
  ignore_patterns = ignore_file.read.split("\n").map(&:strip).reject(&:empty?).map(&:downcase)
  puts "Loaded #{ignore_patterns.length} ignore patterns: #{ignore_patterns.join(', ')}"
else
  puts "No ignore file found at #{ignore_file}"
end

# Function to sort files according to _order.yaml
def sort_by_order_file(files, base_dir)
  # Group files by directory
  grouped = files.group_by { |f| File.dirname(f) }
  sorted_files = []

  # First, handle root-level ordering
  root_order_file = base_dir.join('_order.yaml')
  if root_order_file.exist?
    begin
      root_order = YAML.load_file(root_order_file) || []

      # Process directories in the specified order
      root_order.each do |dir_name|
        dir_path = base_dir.join(dir_name).to_s
        next unless grouped[dir_path]

        # Check for subdirectory order file
        sub_order_file = base_dir.join(dir_name, '_order.yaml')
        if sub_order_file.exist?
          begin
            sub_order = YAML.load_file(sub_order_file) || []
            # Sort files within this directory according to sub_order
            dir_files = grouped[dir_path]
            sorted_dir_files = []

            sub_order.each do |file_base|
              matching_file = dir_files.find { |f| File.basename(f, '.md') == file_base }
              sorted_dir_files << matching_file if matching_file
            end

            # Add any files not in the order list
            remaining = dir_files - sorted_dir_files
            sorted_files.concat(sorted_dir_files + remaining.sort)
          rescue StandardError => e
            puts "Warning: Failed to parse #{sub_order_file}: #{e.message}"
            sorted_files.concat(grouped[dir_path].sort)
          end
        else
          sorted_files.concat(grouped[dir_path].sort)
        end

        grouped.delete(dir_path)
      end
    rescue StandardError => e
      puts "Warning: Failed to parse #{root_order_file}: #{e.message}"
    end
  end

  # Add any remaining files not covered by order files
  grouped.each_value { |files| sorted_files.concat(files.sort) }

  sorted_files
end

# Read all markdown files from content/api directory recursively
if api_content_dir.exist?
  api_files = Dir.glob(api_content_dir.join('**', '*.md')).sort

  # Filter out files matching ignore patterns
  filtered_files = api_files.reject do |file|
    relative_path = Pathname.new(file).relative_path_from(api_content_dir).to_s.downcase

    # Check if any ignore pattern matches the file path
    ignore_patterns.any? do |pattern|
      # Support both exact matches and path contains
      relative_path.include?(pattern) || relative_path.start_with?("#{pattern}/")
    end
  end

  ignored_count = api_files.length - filtered_files.length
  puts "Found #{api_files.length} API documentation files (ignoring #{ignored_count} files)"

  if filtered_files.empty?
    puts 'No markdown files to process after applying ignore patterns'
  else
    # Sort filtered files according to _order.yaml files
    sorted_files = sort_by_order_file(filtered_files, api_content_dir)
    puts 'Sorted files according to _order.yaml configuration'

    hidden_count = 0
    sorted_files.each do |file|
      relative_path = Pathname.new(file).relative_path_from(api_content_dir)
      puts "‚öôÔ∏è  Processing: #{relative_path}"
      content = File.read(file).strip

      # Process all files: remove YAML frontmatter and indent headers
      if content.match(/\A---\n(.*?)\n---\n/m)
        yaml_content = Regexp.last_match(1)

        # Check if file is hidden
        hidden_match = yaml_content.match(/^hidden:\s*(.+)$/i)
        if hidden_match && hidden_match[1].strip.downcase == 'true'
          puts "‚è≠Ô∏è  Skipping hidden file: #{relative_path}"
          hidden_count += 1
          next
        end

        content_without_header = content.sub(/\A---\n.*?\n---\n/m, '').strip

        # Extract title from YAML
        title_match = yaml_content.match(/^title:\s*(.+)$/i)
        if title_match
          title = title_match[1].strip.gsub(/^['"]|['"]$/, '') # Remove quotes if present
          section_counter += 1
          anchor = normalize_anchor(title)
          index_entries << { number: section_counter, title: title, anchor: anchor }
          combined_content << "## #{title}\n\n"
        end

        # Indent all headers by two levels (# -> ###, ## -> ####, etc.)
        indented_content = content_without_header.gsub(/^(#+)/, '##\1')
      else
        # No frontmatter, just indent headers
        indented_content = content.gsub(/^(#+)/, '##\1')
      end
      combined_content << indented_content

      combined_content << "\n\n---\n\n"
    end

    # Remove the last separator
    combined_content[-1] = combined_content[-1].chomp("---\n\n") if combined_content.last.end_with?("---\n\n")
  end
else
  puts "Error: #{api_content_dir} directory not found"
  exit 1
end

# Read and process the reference content
if api_reference_file.exist?
  puts "Reading reference from #{api_reference_file}"
  reference_content = api_reference_file.read.strip

  # Extract endpoint sections from the reference
  reference_lines = reference_content.lines
  processed_reference = []

  # Add a separator before API content
  combined_content << "\n---\n\n"
  combined_content << "## API Reference\n\n"

  reference_lines.each_with_index do |line, idx|
    if line.match(/^### (.+)$/)
      section_title = Regexp.last_match(1).strip
      if section_title != 'Other' # Skip generic sections
        section_counter += 1
        # For the anchor in the index, we need to match how the markdown processor will generate it
        # Most processors convert headers to lowercase and replace spaces with hyphens
        # We'll use normalize_anchor for consistency
        anchor = normalize_anchor(section_title)
        index_entries << { number: section_counter, title: "API: #{section_title}", anchor: anchor }
        # Keep the original title without modifications
        processed_reference << line
      else
        processed_reference << line
      end
    elsif line.match(/^## (.+)$/) && idx == 0
      # Skip the first ## header (Endpoints) as we're replacing it with "API Reference"
      next
    else
      processed_reference << line
    end
  end

  combined_content << processed_reference.join
  combined_content << "\n\n"
else
  puts "Warning: #{api_reference_file} not found"
end

# Generate the index if we have entries
if index_entries.any?
  index_content = +"## √çndice\n"
  index_entries.each do |entry|
    index_content << "#{entry[:number]}. [#{entry[:title]}](##{entry[:anchor]})\n"
  end
  index_content << "\n---\n\n"

  # Insert the index after the main title
  combined_content.insert(1, index_content)
end

# Write the combined content
File.write(output_file, combined_content.join)
puts "\n‚úÖ Done! API documentation generated successfully at: #{output_file}"
puts "üìà Total size: #{File.size(output_file)} bytes"
puts "üìë Generated index with #{index_entries.length} sections" if index_entries.any?
puts "üôà Skipped #{hidden_count} hidden files" if defined?(hidden_count) && hidden_count.positive?
